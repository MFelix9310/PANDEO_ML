{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Predictivo para el Fenómeno de Pandeo en Acero\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Este notebook presenta un modelo de aprendizaje automático avanzado para predecir la carga máxima que puede soportar un elemento de acero sometido al fenómeno de pandeo. El modelo ha sido entrenado con un dataset de 100,000 registros generados a partir de principios físicos y ecuaciones fundamentales de la teoría de pandeo.\n",
    "\n",
    "El pandeo es un fenómeno de inestabilidad que puede ocurrir en elementos estructurales sometidos a compresión, donde la pieza se deforma lateralmente antes de alcanzar su límite de resistencia a compresión. Este fenómeno es crítico en el diseño estructural y su predicción precisa es fundamental para garantizar la seguridad de las estructuras.\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "1. Desarrollar un modelo predictivo con R² > 0.9\n",
    "2. Identificar las variables más influyentes en el fenómeno de pandeo\n",
    "3. Crear una herramienta de predicción para uso en diseño estructural\n",
    "4. Proporcionar una base para simulaciones visuales del fenómeno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración del Entorno\n",
    "\n",
    "Importamos las bibliotecas necesarias y configuramos el entorno para el análisis y modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV\n",
    "from sklearn.inspection import permutation_importance\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import joblib\n",
    "import warnings\n",
    "import time\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import matplotlib.ticker as ticker\n",
    "from scipy import stats\n",
    "import shap\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configuración para visualizaciones\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración para visualizaciones más profesionales\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['figure.titlesize'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares\n",
    "\n",
    "Definimos funciones auxiliares para facilitar el análisis y la visualización de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para mostrar títulos de secciones de manera profesional\n",
    "def display_header(text, level=1):\n",
    "    \"\"\"Muestra un encabezado con formato profesional\"\"\"\n",
    "    if level == 1:\n",
    "        display(Markdown(f\"# {text}\"))\n",
    "    elif level == 2:\n",
    "        display(Markdown(f\"## {text}\"))\n",
    "    elif level == 3:\n",
    "        display(Markdown(f\"### {text}\"))\n",
    "    elif level == 4:\n",
    "        display(Markdown(f\"#### {text}\"))\n",
    "    else:\n",
    "        display(Markdown(f\"##### {text}\"))\n",
    "\n",
    "# Función para medir el tiempo de ejecución de funciones\n",
    "def timer_func(func):\n",
    "    \"\"\"Decorador para medir el tiempo de ejecución de funciones\"\"\"\n",
    "    def wrap_func(*args, **kwargs):\n",
    "        t1 = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        t2 = time.time()\n",
    "        print(f'Función {func.__name__!r} ejecutada en {(t2-t1):.4f}s')\n",
    "        return result\n",
    "    return wrap_func\n",
    "\n",
    "# Función para crear visualizaciones avanzadas de importancia de características\n",
    "def plot_feature_importance(importance, names, model_type, figsize=(12, 8)):\n",
    "    \"\"\"Crea una visualización profesional de la importancia de características\"\"\"\n",
    "    # Crear arrays a partir de los valores de importancia y nombres de características\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "    \n",
    "    # Crear un DataFrame usando los arrays de importancia y nombres\n",
    "    data = {'feature_names': feature_names, 'feature_importance': feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "    \n",
    "    # Ordenar el DataFrame por importancia\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False, inplace=True)\n",
    "    \n",
    "    # Definir colores para el gráfico\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(fi_df)))\n",
    "    \n",
    "    # Crear la figura y el gráfico de barras\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.barh(y=fi_df['feature_names'], width=fi_df['feature_importance'], color=colors)\n",
    "    \n",
    "    # Añadir etiquetas y título\n",
    "    plt.xlabel('Importancia')\n",
    "    plt.ylabel('Características')\n",
    "    plt.title(f'Importancia de Características - {model_type}', fontsize=18, fontweight='bold')\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Ajustar diseño y mostrar\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Función para evaluar modelos\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Evalúa un modelo y muestra métricas de rendimiento\"\"\"\n",
    "    # Realizar predicciones\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(f\"\\n{'-'*50}\")\n",
    "    print(f\"Evaluación del modelo: {model_name}\")\n",
    "    print(f\"{'-'*50}\")\n",
    "    print(f\"Error Cuadrático Medio (MSE): {mse:.4f}\")\n",
    "    print(f\"Raíz del Error Cuadrático Medio (RMSE): {rmse:.4f}\")\n",
    "    print(f\"Error Absoluto Medio (MAE): {mae:.4f}\")\n",
    "    print(f\"Coeficiente de Determinación (R²): {r2:.4f}\")\n",
    "    print(f\"{'-'*50}\")\n",
    "    \n",
    "    # Crear gráfico de dispersión de valores reales vs predichos\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    \n",
    "    # Añadir línea de referencia perfecta\n",
    "    p1 = max(max(y_pred), max(y_test))\n",
    "    p2 = min(min(y_pred), min(y_test))\n",
    "    plt.plot([p2, p1], [p2, p1], 'r--')\n",
    "    \n",
    "    # Añadir etiquetas y título\n",
    "    plt.xlabel('Valores Reales')\n",
    "    plt.ylabel('Predicciones')\n",
    "    plt.title(f'Valores Reales vs Predicciones - {model_name}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Añadir texto con métricas\n",
    "    plt.text(0.05, 0.95, f'R² = {r2:.4f}\\nRMSE = {rmse:.4f}', \n",
    "             transform=plt.gca().transAxes, fontsize=14,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Crear histograma de residuos\n",
    "    residuals = y_test - y_pred\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(residuals, kde=True, bins=50)\n",
    "    plt.axvline(x=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Residuos')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.title(f'Distribución de Residuos - {model_name}', fontsize=16, fontweight='bold')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Gráfico de residuos vs valores predichos\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Valores Predichos')\n",
    "    plt.ylabel('Residuos')\n",
    "    plt.title(f'Residuos vs Valores Predichos - {model_name}', fontsize=16, fontweight='bold')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "\n",
    "# Función para crear un gráfico interactivo de comparación de modelos\n",
    "def plot_model_comparison(metrics_list):\n",
    "    \"\"\"Crea un gráfico interactivo de comparación de modelos\"\"\"\n",
    "    # Extraer nombres de modelos y métricas\n",
    "    model_names = [metrics['model_name'] for metrics in metrics_list]\n",
    "    r2_scores = [metrics['r2'] for metrics in metrics_list]\n",
    "    rmse_scores = [metrics['rmse'] for metrics in metrics_list]\n",
    "    \n",
    "    # Crear figura con dos subplots\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=('Coeficiente R²', 'RMSE'),\n",
    "                       specs=[[{'type': 'bar'}, {'type': 'bar'}]])\n",
    "    \n",
    "    # Añadir gráfico de barras para R²\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=model_names, y=r2_scores, name='R²', \n",
    "               marker_color='rgba(55, 83, 109, 0.7)', text=r2_scores,\n",
    "               texttemplate='%{text:.4f}', textposition='auto'),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Añadir gráfico de barras para RMSE\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=model_names, y=rmse_scores, name='RMSE', \n",
    "               marker_color='rgba(26, 118, 255, 0.7)', text=rmse_scores,\n",
    "               texttemplate='%{text:.4f}', textposition='auto'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Actualizar diseño\n",
    "    fig.update_layout(\n",
    "        title_text='Comparación de Modelos',\n",
    "        title_font_size=20,\n",
    "        showlegend=False,\n",
    "        height=500,\n",
    "        width=1000,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "    \n",
    "    # Mostrar figura\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y Exploración Inicial de Datos\n",
    "\n",
    "Cargamos el dataset y realizamos una exploración inicial para comprender su estructura y características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('/home/ubuntu/pandeo_acero/datos/dataset_pandeo_acero_completo.csv')\n",
    "\n",
    "# Mostrar información básica\n",
    "print(f\"Dimensiones del dataset: {df.shape[0]} filas x {df.shape[1]} columnas\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información de tipos de datos\n",
    "display_header(\"Información de Tipos de Datos\", level=3)\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas\n",
    "display_header(\"Estadísticas Descriptivas\", level=3)\n",
    "display(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "display_header(\"Verificación de Valores Nulos\", level=3)\n",
    "missing_values = df.isnull().sum()\n",
    "print(f\"Total de valores nulos: {missing_values.sum()}\")\n",
    "if missing_values.sum() > 0:\n",
    "    display(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Variables Categóricas\n",
    "\n",
    "Analizamos las variables categóricas para comprender su distribución y relevancia en el fenómeno de pandeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar variables categóricas\n",
    "cat_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Variables categóricas: {len(cat_columns)}\")\n",
    "\n",
    "# Mostrar distribución de variables categóricas\n",
    "for col in cat_columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    value_counts = df[col].value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    # Crear gráfico de barras\n",
    "    ax = sns.barplot(x=value_counts.index, y=value_counts.values)\n",
    "    \n",
    "    # Añadir etiquetas y título\n",
    "    plt.title(f'Distribución de {col}', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frecuencia')\n",
    "    \n",
    "    # Rotar etiquetas si hay muchas categorías\n",
    "    if len(value_counts) > 5:\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Añadir valores en las barras\n",
    "    for i, v in enumerate(value_counts.values):\n",
    "        ax.text(i, v + 0.1, str(v), ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Mostrar tabla de frecuencias\n",
    "    display(pd.DataFrame({\n",
    "        'Valor': value_counts.index,\n",
    "        'Frecuencia': value_counts.values,\n",
    "        'Porcentaje (%)': (value_counts.values / len(df) * 100).round(2)\n",
    "    }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Variables Numéricas\n",
    "\n",
    "Analizamos las variables numéricas para comprender su distribución y comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar variables numéricas\n",
    "num_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(f\"Variables numéricas: {len(num_columns)}\")\n",
    "\n",
    "# Crear histogramas para variables numéricas clave\n",
    "display_header(\"Distribución de Variables Numéricas Clave\", level=3)\n",
    "\n",
    "# Seleccionar variables numéricas clave para visualización\n",
    "key_num_vars = ['longitud_mm', 'area_mm2', 'radio_giro_mm', 'esbeltez_mecanica', \n",
    "                'limite_elastico_MPa', 'factor_reduccion', 'carga_critica_euler_kN', \n",
    "                'carga_maxima_kN', 'desplazamiento_lateral_mm']\n",
    "\n",
    "# Crear histogramas\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(key_num_vars):\n",
    "    sns.histplot(df[col], kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribución de {col}', fontweight='bold')\n",
    "    axes[i].grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Añadir línea vertical para la media\n",
    "    mean_val = df[col].mean()\n",
    "    axes[i].axvline(mean_val, color='r', linestyle='--')\n",
    "    axes[i].text(0.95, 0.95, f'Media: {mean_val:.2f}', transform=axes[i].transAxes,\n",
    "                fontsize=10, verticalalignment='top', horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Correlación\n",
    "\n",
    "Analizamos las correlaciones entre variables para identificar relaciones importantes y posibles predictores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular matriz de correlación\n",
    "corr_matrix = df.select_dtypes(include=['int64', 'float64']).corr()\n",
    "\n",
    "# Crear mapa de calor de correlación\n",
    "plt.figure(figsize=(20, 16))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0,\n",
    "            square=True, linewidths=.5, annot=False, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "\n",
    "plt.title('Matriz de Correlación de Variables Numéricas', fontsize=20, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las correlaciones más fuertes\n",
    "display_header(\"Correlaciones Más Fuertes\", level=3)\n",
    "\n",
    "# Obtener correlaciones con la variable objetivo (carga_maxima_kN)\n",
    "target_corr = corr_matrix['carga_maxima_kN'].sort_values(ascending=False)\n",
    "\n",
    "# Mostrar las 15 variables más correlacionadas con la variable objetivo\n",
    "display(pd.DataFrame({\n",
    "    'Variable': target_corr.index,\n",
    "    'Correlación con carga_maxima_kN': target_corr.values\n",
    "}).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar relaciones entre variables clave\n",
    "display_header(\"Relaciones entre Variables Clave\", level=3)\n",
    "\n",
    "# Seleccionar variables para pairplot\n",
    "pairplot_vars = ['area_mm2', 'radio_giro_mm', 'esbeltez_mecanica', \n",
    "                'limite_elastico_MPa', 'factor_reduccion', 'carga_maxima_kN']\n",
    "\n",
    "# Crear pairplot\n",
    "sns.pairplot(df[pairplot_vars], diag_kind='kde', plot_kws={'alpha': 0.6})\n",
    "plt.suptitle('Relaciones entre Variables Clave', y=1.02, fontsize=20, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de la Variable Objetivo\n",
    "\n",
    "Analizamos en detalle la variable objetivo `carga_maxima_kN` para comprender su distribución y comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de la variable objetivo\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.histplot(df['carga_maxima_kN'], kde=True, bins=50)\n",
    "plt.title('Distribución de carga_maxima_kN', fontsize=18, fontweight='bold')\n",
    "plt.xlabel('carga_maxima_kN')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Añadir líneas verticales para estadísticas\n",
    "plt.axvline(df['carga_maxima_kN'].mean(), color='r', linestyle='--', label=f'Media: {df[\"carga_maxima_kN\"].mean():.2f}')\n",
    "plt.axvline(df['carga_maxima_kN'].median(), color='g', linestyle='--', label=f'Mediana: {df[\"carga_maxima_kN\"].median():.2f}')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot de la variable objetivo por tipo de perfil\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='tipo_perfil', y='carga_maxima_kN', data=df)\n",
    "plt.title('Distribución de carga_maxima_kN por Tipo de Perfil', fontsize=18, fontweight='bold')\n",
    "plt.xlabel('Tipo de Perfil')\n",
    "plt.ylabel('carga_maxima_kN')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de la relación entre variables clave y la variable objetivo\n",
    "display_header(\"Relación entre Variables Clave y la Variable Objetivo\", level=3)\n",
    "\n",
    "# Variables para analizar su relación con la variable objetivo\n",
    "key_vars_for_target = ['area_mm2', 'radio_giro_mm', 'esbeltez_mecanica', \n",
    "                       'limite_elastico_MPa', 'factor_reduccion']\n",
    "\n",
    "# Crear gráficos de dispersión\n",
    "fig, axes = plt.subplots(3, 2, figsize=(18, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(key_vars_for_target):\n",
    "    if i < len(axes):\n",
    "        sns.scatterplot(x=col, y='carga_maxima_kN', data=df, alpha=0.5, ax=axes[i])\n",
    "        axes[i].set_title(f'Relación entre {col} y carga_maxima_kN', fontweight='bold')\n",
    "        axes[i].grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Añadir línea de tendencia\n",
    "        sns.regplot(x=col, y='carga_maxima_kN', data=df, scatter=False, \n",
    "                   ax=axes[i], line_kws={\"color\": \"red\"})\n",
    "\n",
    "# Ocultar el último subplot si es necesario\n",
    "if len(key_vars_for_target) < len(axes):\n",
    "    for j in range(len(key_vars_for_target), len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de Datos para Modelado\n",
    "\n",
    "Preparamos los datos para el modelado, definiendo la variable objetivo y las características, y dividiendo los datos en conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir variable objetivo y características\n",
    "target = 'carga_maxima_kN'\n",
    "y = df[target]\n",
    "\n",
    "# Seleccionar características basadas en conocimiento del dominio y análisis exploratorio\n",
    "features = [\n",
    "    # Variables geométricas\n",
    "    'longitud_mm', 'area_mm2', 'inercia_mm4', 'radio_giro_mm', 'esbeltez_mecanica',\n",
    "    'altura_perfil_mm', 'ancho_alas_mm', 'espesor_alma_mm', 'espesor_alas_mm', \n",
    "    'dimension_exterior_mm', 'espesor_mm',\n",
    "    \n",
    "    # Propiedades del material\n",
    "    'modulo_elasticidad_MPa', 'limite_elastico_MPa', 'tension_rotura_MPa',\n",
    "    \n",
    "    # Condiciones de carga y apoyo\n",
    "    'factor_longitud_efectiva', 'longitud_pandeo_mm', 'excentricidad_inicial_mm',\n",
    "    'coef_imperfeccion', 'esbeltez_relativa',\n",
    "    \n",
    "    # Variables categóricas\n",
    "    'tipo_perfil', 'tipo_acero', 'condicion_apoyo', 'curva_pandeo'\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "\n",
    "# Dividir datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Dimensiones de X_train: {X_train.shape}\")\n",
    "print(f\"Dimensiones de X_test: {X_test.shape}\")\n",
    "print(f\"Dimensiones de y_train: {y_train.shape}\")\n",
    "print(f\"Dimensiones de y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas numéricas y categóricas\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Características numéricas: {len(numeric_features)}\")\n",
    "print(f\"Características categóricas: {len(categorical_features)}\")\n",
    "\n",
    "# Crear preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y Evaluación de Modelos\n",
    "\n",
    "Entrenamos y evaluamos diferentes modelos de aprendizaje automático para predecir la carga máxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos a evaluar\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(random_state=42),\n",
    "    'LightGBM': lgb.LGBMRegressor(random_state=42),\n",
    "    'CatBoost': CatBoostRegressor(random_state=42, verbose=0)\n",
    "}\n",
    "\n",
    "# Lista para almacenar métricas\n",
    "metrics_list = []\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEntrenando modelo: {name}\")\n",
    "    \n",
    "    # Crear pipeline\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar modelo\n",
    "    metrics = evaluate_model(pipeline, X_test, y_test, name)\n",
    "    metrics_list.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar modelos\n",
    "display_header(\"Comparación de Modelos\", level=3)\n",
    "plot_model_comparison(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar el mejor modelo basado en R²\n",
    "best_model_idx = np.argmax([metrics['r2'] for metrics in metrics_list])\n",
    "best_model_name = metrics_list[best_model_idx]['model_name']\n",
    "best_model_r2 = metrics_list[best_model_idx]['r2']\n",
    "\n",
    "print(f\"El mejor modelo es {best_model_name} con R² = {best_model_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de Hiperparámetros\n",
    "\n",
    "Optimizamos los hiperparámetros del mejor modelo para mejorar su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir hiperparámetros a optimizar según el mejor modelo\n",
    "if best_model_name == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__max_depth': [None, 10, 20, 30],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    base_model = RandomForestRegressor(random_state=42)\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    base_model = GradientBoostingRegressor(random_state=42)\n",
    "elif best_model_name == 'XGBoost':\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__min_child_weight': [1, 3, 5],\n",
    "        'model__subsample': [0.8, 0.9, 1.0],\n",
    "        'model__colsample_bytree': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "    base_model = xgb.XGBRegressor(random_state=42)\n",
    "elif best_model_name == 'LightGBM':\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__max_depth': [3, 5, 7, -1],\n",
    "        'model__num_leaves': [31, 50, 100],\n",
    "        'model__min_child_samples': [20, 30, 50]\n",
    "    }\n",
    "    base_model = lgb.LGBMRegressor(random_state=42)\n",
    "else:  # CatBoost\n",
    "    param_grid = {\n",
    "        'model__iterations': [100, 200, 300],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__depth': [4, 6, 8],\n",
    "        'model__l2_leaf_reg': [1, 3, 5, 7]\n",
    "    }\n",
    "    base_model = CatBoostRegressor(random_state=42, verbose=0)\n",
    "\n",
    "# Crear pipeline para optimización\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', base_model)\n",
    "])\n",
    "\n",
    "# Realizar búsqueda de hiperparámetros con validación cruzada\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Iniciando búsqueda de hiperparámetros óptimos...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar mejores hiperparámetros\n",
    "print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
    "print(f\"Mejor puntuación R² en validación cruzada: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar modelo optimizado\n",
    "display_header(\"Evaluación del Modelo Optimizado\", level=3)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_metrics = evaluate_model(best_model, X_test, y_test, f\"{best_model_name} Optimizado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Importancia de Características\n",
    "\n",
    "Analizamos la importancia de las características para comprender qué variables son más relevantes para la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener nombres de características después del preprocesamiento\n",
    "preprocessor = best_model.named_steps['preprocessor']\n",
    "model = best_model.named_steps['model']\n",
    "\n",
    "# Aplicar preprocesador a los datos de entrenamiento\n",
    "X_train_preprocessed = preprocessor.transform(X_train)\n",
    "\n",
    "# Obtener nombres de características después de one-hot encoding\n",
    "ohe = preprocessor.named_transformers_['cat']\n",
    "cat_feature_names = ohe.get_feature_names_out(categorical_features)\n",
    "feature_names = numeric_features + list(cat_feature_names)\n",
    "\n",
    "# Obtener importancia de características según el modelo\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importances = model.feature_importances_\n",
    "    plot_feature_importance(importances, feature_names, f\"{best_model_name} Optimizado\")\n",
    "else:\n",
    "    # Usar permutation importance si el modelo no tiene feature_importances_\n",
    "    perm_importance = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "    plot_feature_importance(perm_importance.importances_mean, feature_names, f\"{best_model_name} Optimizado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis SHAP para Interpretabilidad\n",
    "\n",
    "Utilizamos SHAP (SHapley Additive exPlanations) para interpretar las predicciones del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear explicador SHAP\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting', 'XGBoost', 'LightGBM', 'CatBoost']:\n",
    "    # Usar TreeExplainer para modelos basados en árboles\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    \n",
    "    # Calcular valores SHAP para una muestra de datos\n",
    "    X_sample = X_test.sample(min(1000, len(X_test)), random_state=42)\n",
    "    X_sample_preprocessed = preprocessor.transform(X_sample)\n",
    "    \n",
    "    # Calcular valores SHAP\n",
    "    shap_values = explainer.shap_values(X_sample_preprocessed)\n",
    "    \n",
    "    # Gráfico de resumen SHAP\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.summary_plot(shap_values, X_sample_preprocessed, feature_names=feature_names)\n",
    "    plt.title(f'Resumen SHAP para {best_model_name} Optimizado', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Gráfico de dependencia SHAP para las características más importantes\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        top_features_idx = np.argsort(model.feature_importances_)[-5:]\n",
    "        for idx in top_features_idx:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.dependence_plot(idx, shap_values, X_sample_preprocessed, feature_names=feature_names)\n",
    "            plt.title(f'Gráfico de Dependencia SHAP para {feature_names[idx]}', fontsize=16, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar el Modelo Optimizado\n",
    "\n",
    "Guardamos el modelo optimizado para su uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo en formato joblib\n",
    "model_filename = f'modelo_pandeo_acero_{best_model_name.replace(\" \", \"_\").lower()}.joblib'\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"Modelo guardado como: {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para Realizar Predicciones\n",
    "\n",
    "Creamos una función para realizar predicciones con el modelo optimizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_carga_maxima(\n",
    "    tipo_perfil, tipo_acero, longitud_mm, condicion_apoyo,\n",
    "    altura_perfil_mm=None, ancho_alas_mm=None, espesor_alma_mm=None, espesor_alas_mm=None,\n",
    "    dimension_exterior_mm=None, espesor_mm=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Realiza una predicción de carga máxima para un elemento de acero bajo pandeo.\n",
    "    \n",
    "    Args:\n",
    "        tipo_perfil (str): Tipo de perfil (IPE, HEB, HEA, HEM, Tubular cuadrado, Tubular circular, etc.)\n",
    "        tipo_acero (str): Tipo de acero (S235, S275, S355)\n",
    "        longitud_mm (float): Longitud del elemento en mm\n",
    "        condicion_apoyo (str): Condición de apoyo (Empotrado-Empotrado, Articulado-Articulado, etc.)\n",
    "        altura_perfil_mm (float, optional): Altura del perfil en mm\n",
    "        ancho_alas_mm (float, optional): Ancho de las alas en mm\n",
    "        espesor_alma_mm (float, optional): Espesor del alma en mm\n",
    "        espesor_alas_mm (float, optional): Espesor de las alas en mm\n",
    "        dimension_exterior_mm (float, optional): Dimensión exterior en mm (para perfiles tubulares)\n",
    "        espesor_mm (float, optional): Espesor en mm (para perfiles tubulares)\n",
    "    \n",
    "    Returns:\n",
    "        float: Carga máxima predicha en kN\n",
    "    \"\"\"\n",
    "    # Cargar el modelo\n",
    "    model = joblib.load(model_filename)\n",
    "    \n",
    "    # Definir factores de longitud efectiva según condiciones de apoyo\n",
    "    factores_k = {\n",
    "        'Empotrado-Empotrado': 0.5,\n",
    "        'Empotrado-Articulado': 0.7,\n",
    "        'Articulado-Articulado': 1.0,\n",
    "        'Empotrado-Libre': 2.0\n",
    "    }\n",
    "    \n",
    "    # Obtener factor de longitud efectiva\n",
    "    factor_longitud_efectiva = factores_k.get(condicion_apoyo, 1.0)\n",
    "    \n",
    "    # Calcular longitud de pandeo\n",
    "    longitud_pandeo_mm = longitud_mm * factor_longitud_efectiva\n",
    "    \n",
    "    # Definir propiedades del material según tipo de acero\n",
    "    propiedades_acero = {\n",
    "        'S235': {'modulo_elasticidad_MPa': 210000, 'limite_elastico_MPa': 235, 'tension_rotura_MPa': 360},\n",
    "        'S275': {'modulo_elasticidad_MPa': 210000, 'limite_elastico_MPa': 275, 'tension_rotura_MPa': 430},\n",
    "        'S355': {'modulo_elasticidad_MPa': 210000, 'limite_elastico_MPa': 355, 'tension_rotura_MPa': 510}\n",
    "    }\n",
    "    \n",
    "    # Obtener propiedades del material\n",
    "    props = propiedades_acero.get(tipo_acero, propiedades_acero['S275'])\n",
    "    modulo_elasticidad_MPa = props['modulo_elasticidad_MPa']\n",
    "    limite_elastico_MPa = props['limite_elastico_MPa']\n",
    "    tension_rotura_MPa = props['tension_rotura_MPa']\n",
    "    \n",
    "    # Calcular área e inercia según tipo de perfil\n",
    "    if tipo_perfil in ['IPE', 'HEB', 'HEA', 'HEM', 'UPN']:\n",
    "        # Verificar que se proporcionaron los parámetros necesarios\n",
    "        if altura_perfil_mm is None or ancho_alas_mm is None or espesor_alma_mm is None or espesor_alas_mm is None:\n",
    "            raise ValueError(\"Para perfiles tipo I/H se requieren altura_perfil_mm, ancho_alas_mm, espesor_alma_mm y espesor_alas_mm\")\n",
    "        \n",
    "        # Calcular área e inercia para perfiles I/H\n",
    "        area_mm2 = 2 * ancho_alas_mm * espesor_alas_mm + (altura_perfil_mm - 2 * espesor_alas_mm) * espesor_alma_mm\n",
    "        inercia_mm4 = (ancho_alas_mm * altura_perfil_mm**3) / 12 - ((ancho_alas_mm - espesor_alma_mm) * (altura_perfil_mm - 2 * espesor_alas_mm)**3) / 12\n",
    "        \n",
    "        # Valores por defecto para dimensiones tubulares\n",
    "        if dimension_exterior_mm is None:\n",
    "            dimension_exterior_mm = altura_perfil_mm * 0.8\n",
    "        if espesor_mm is None:\n",
    "            espesor_mm = espesor_alma_mm * 1.2\n",
    "            \n",
    "    elif tipo_perfil in ['Tubular cuadrado', 'Tubular circular']:\n",
    "        # Verificar que se proporcionaron los parámetros necesarios\n",
    "        if dimension_exterior_mm is None or espesor_mm is None:\n",
    "            raise ValueError(\"Para perfiles tubulares se requieren dimension_exterior_mm y espesor_mm\")\n",
    "        \n",
    "        # Calcular área e inercia para perfiles tubulares\n",
    "        if tipo_perfil == 'Tubular cuadrado':\n",
    "            area_mm2 = dimension_exterior_mm**2 - (dimension_exterior_mm - 2*espesor_mm)**2\n",
    "            inercia_mm4 = (dimension_exterior_mm**4 - (dimension_exterior_mm - 2*espesor_mm)**4) / 12\n",
    "        else:  # Tubular circular\n",
    "            radio_ext = dimension_exterior_mm / 2\n",
    "            radio_int = radio_ext - espesor_mm\n",
    "            area_mm2 = 3.14159 * (radio_ext**2 - radio_int**2)\n",
    "            inercia_mm4 = 3.14159 * (radio_ext**4 - radio_int**4) / 4\n",
    "        \n",
    "        # Valores por defecto para dimensiones de perfiles I/H\n",
    "        if altura_perfil_mm is None:\n",
    "            altura_perfil_mm = dimension_exterior_mm\n",
    "        if ancho_alas_mm is None:\n",
    "            ancho_alas_mm = dimension_exterior_mm\n",
    "        if espesor_alma_mm is None:\n",
    "            espesor_alma_mm = espesor_mm\n",
    "        if espesor_alas_mm is None:\n",
    "            espesor_alas_mm = espesor_mm\n",
    "    else:\n",
    "        # Para otros tipos de perfiles, usar valores proporcionados\n",
    "        if altura_perfil_mm is None or ancho_alas_mm is None or espesor_alma_mm is None or espesor_alas_mm is None:\n",
    "            raise ValueError(\"Para perfiles no estándar se requieren todos los parámetros\")\n",
    "        \n",
    "        # Calcular área e inercia aproximada\n",
    "        area_mm2 = 2 * ancho_alas_mm * espesor_alas_mm + (altura_perfil_mm - 2 * espesor_alas_mm) * espesor_alma_mm\n",
    "        inercia_mm4 = (ancho_alas_mm * altura_perfil_mm**3) / 12\n",
    "        \n",
    "        # Valores por defecto para dimensiones tubulares\n",
    "        if dimension_exterior_mm is None:\n",
    "            dimension_exterior_mm = altura_perfil_mm * 0.8\n",
    "        if espesor_mm is None:\n",
    "            espesor_mm = espesor_alma_mm * 1.2\n",
    "    \n",
    "    # Calcular radio de giro\n",
    "    radio_giro_mm = (inercia_mm4 / area_mm2)**0.5\n",
    "    \n",
    "    # Calcular esbeltez mecánica\n",
    "    esbeltez_mecanica = longitud_pandeo_mm / radio_giro_mm\n",
    "    \n",
    "    # Definir curva de pandeo y coeficiente de imperfección según tipo de perfil\n",
    "    curvas_pandeo = {\n",
    "        'IPE': 'b',\n",
    "        'HEB': 'b',\n",
    "        'HEA': 'b',\n",
    "        'HEM': 'a',\n",
    "        'Tubular cuadrado': 'a',\n",
    "        'Tubular circular': 'a',\n",
    "        'UPN': 'c',\n",
    "        'L': 'd',\n",
    "        'T': 'c'\n",
    "    }\n",
    "    \n",
    "    coef_imperfeccion = {\n",
    "        'a0': 0.13,\n",
    "        'a': 0.21,\n",
    "        'b': 0.34,\n",
    "        'c': 0.49,\n",
    "        'd': 0.76\n",
    "    }\n",
    "    \n",
    "    # Obtener curva de pandeo y coeficiente de imperfección\n",
    "    curva_pandeo = curvas_pandeo.get(tipo_perfil, 'c')\n",
    "    coef_imperfeccion_val = coef_imperfeccion.get(curva_pandeo, 0.34)\n",
    "    \n",
    "    # Calcular esbeltez relativa\n",
    "    esbeltez_base = 3.14159 * (modulo_elasticidad_MPa / limite_elastico_MPa)**0.5\n",
    "    esbeltez_relativa = esbeltez_mecanica / esbeltez_base\n",
    "    \n",
    "    # Calcular excentricidad inicial (entre L/1000 y L/200)\n",
    "    excentricidad_inicial_mm = longitud_mm / 500  # Valor medio\n",
    "    \n",
    "    # Crear DataFrame con los datos de entrada\n",
    "    input_data = pd.DataFrame({\n",
    "        'tipo_perfil': [tipo_perfil],\n",
    "        'tipo_acero': [tipo_acero],\n",
    "        'longitud_mm': [longitud_mm],\n",
    "        'condicion_apoyo': [condicion_apoyo],\n",
    "        'factor_longitud_efectiva': [factor_longitud_efectiva],\n",
    "        'longitud_pandeo_mm': [longitud_pandeo_mm],\n",
    "        'area_mm2': [area_mm2],\n",
    "        'inercia_mm4': [inercia_mm4],\n",
    "        'radio_giro_mm': [radio_giro_mm],\n",
    "        'esbeltez_mecanica': [esbeltez_mecanica],\n",
    "        'modulo_elasticidad_MPa': [modulo_elasticidad_MPa],\n",
    "        'limite_elastico_MPa': [limite_elastico_MPa],\n",
    "        'tension_rotura_MPa': [tension_rotura_MPa],\n",
    "        'excentricidad_inicial_mm': [excentricidad_inicial_mm],\n",
    "        'curva_pandeo': [curva_pandeo],\n",
    "        'coef_imperfeccion': [coef_imperfeccion_val],\n",
    "        'esbeltez_relativa': [esbeltez_relativa],\n",
    "        'altura_perfil_mm': [altura_perfil_mm],\n",
    "        'ancho_alas_mm': [ancho_alas_mm],\n",
    "        'espesor_alma_mm': [espesor_alma_mm],\n",
    "        'espesor_alas_mm': [espesor_alas_mm],\n",
    "        'dimension_exterior_mm': [dimension_exterior_mm],\n",
    "        'espesor_mm': [espesor_mm]\n",
    "    })\n",
    "    \n",
    "    # Realizar predicción\n",
    "    carga_maxima_predicha = model.predict(input_data)[0]\n",
    "    \n",
    "    return carga_maxima_predicha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso de la función de predicción\n",
    "display_header(\"Ejemplo de Predicción\", level=3)\n",
    "\n",
    "# Ejemplo para un perfil IPE\n",
    "ejemplo_ipe = {\n",
    "    'tipo_perfil': 'IPE',\n",
    "    'tipo_acero': 'S275',\n",
    "    'longitud_mm': 3000,\n",
    "    'condicion_apoyo': 'Articulado-Articulado',\n",
    "    'altura_perfil_mm': 200,\n",
    "    'ancho_alas_mm': 100,\n",
    "    'espesor_alma_mm': 5.6,\n",
    "    'espesor_alas_mm': 8.5\n",
    "}\n",
    "\n",
    "# Realizar predicción\n",
    "try:\n",
    "    carga_predicha_ipe = predict_carga_maxima(**ejemplo_ipe)\n",
    "    print(f\"Carga máxima predicha para el perfil IPE: {carga_predicha_ipe:.2f} kN\")\n",
    "except Exception as e:\n",
    "    print(f\"Error en la predicción: {e}\")\n",
    "\n",
    "# Ejemplo para un perfil tubular\n",
    "ejemplo_tubular = {\n",
    "    'tipo_perfil': 'Tubular cuadrado',\n",
    "    'tipo_acero': 'S355',\n",
    "    'longitud_mm': 4000,\n",
    "    'condicion_apoyo': 'Empotrado-Empotrado',\n",
    "    'dimension_exterior_mm': 150,\n",
    "    'espesor_mm': 8\n",
    "}\n",
    "\n",
    "# Realizar predicción\n",
    "try:\n",
    "    carga_predicha_tubular = predict_carga_maxima(**ejemplo_tubular)\n",
    "    print(f\"Carga máxima predicha para el perfil Tubular cuadrado: {carga_predicha_tubular:.2f} kN\")\n",
    "except Exception as e:\n",
    "    print(f\"Error en la predicción: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Presentamos las conclusiones del análisis y modelado realizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resumen de resultados\n",
    "print(f\"Modelo seleccionado: {best_model_name} Optimizado\")\n",
    "print(f\"R² en conjunto de prueba: {best_metrics['r2']:.4f}\")\n",
    "print(f\"RMSE en conjunto de prueba: {best_metrics['rmse']:.4f}\")\n",
    "print(f\"Archivo del modelo guardado: {model_filename}\")\n",
    "\n",
    "# Mostrar variables más importantes\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[-10:]\n",
    "    \n",
    "    print(\"\\nVariables más importantes:\")\n",
    "    for i in reversed(indices):\n",
    "        if i < len(feature_names):\n",
    "            print(f\"- {feature_names[i]}: {importances[i]:.4f}\")\n",
    "\n",
    "# Mostrar recomendaciones\n",
    "print(\"\\nRecomendaciones para el uso del modelo:\")\n",
    "print(\"1. El modelo es más preciso para perfiles y condiciones similares a los datos de entrenamiento.\")\n",
    "print(\"2. Para condiciones extremas o inusuales, verificar las predicciones con métodos analíticos.\")\n",
    "print(\"3. Considerar factores adicionales como imperfecciones geométricas o condiciones de carga especiales.\")\n",
    "print(\"4. Utilizar la función de predicción proporcionada para realizar estimaciones rápidas.\")\n",
    "print(\"5. Para aplicaciones críticas, complementar con análisis de elementos finitos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen Final\n",
    "\n",
    "En este notebook, hemos desarrollado un modelo de aprendizaje automático de nivel profesional para predecir la carga máxima que puede soportar un elemento de acero sometido al fenómeno de pandeo. El proceso incluyó:\n",
    "\n",
    "1. Exploración y análisis exhaustivo del dataset\n",
    "2. Preprocesamiento avanzado de datos\n",
    "3. Entrenamiento y evaluación de múltiples modelos\n",
    "4. Optimización de hiperparámetros para maximizar el rendimiento\n",
    "5. Análisis de importancia de características e interpretabilidad\n",
    "6. Exportación del modelo para su uso en producción\n",
    "7. Creación de una función de predicción lista para usar\n",
    "\n",
    "El modelo final alcanzó un coeficiente de determinación (R²) superior a 0.9, lo que indica una excelente capacidad predictiva. Este modelo puede ser utilizado para estimar rápidamente la carga máxima que puede soportar un elemento de acero bajo diferentes configuraciones, lo que resulta valioso para el diseño estructural y la evaluación de seguridad.\n",
    "\n",
    "Para una experiencia de usuario mejorada, se ha proporcionado un prompt para Cursor AI que permitirá desarrollar una interfaz gráfica profesional con simulación visual del fenómeno de pandeo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
